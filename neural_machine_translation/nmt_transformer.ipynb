{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_file = \"eng-ban.txt\"\n",
    "text_file = \"ban-eng.txt\"\n",
    "# To open the text file we need to encode the text. Here, we use 'utf8' encoding\n",
    "with open(text_file, encoding=\"utf8\") as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "text_pairs = []\n",
    "for line in lines:\n",
    "    bangla, english = line.split(\" >>> \")\n",
    "    bangla = \"[start] \" + bangla + \" [end]\"\n",
    "    text_pairs.append((english, bangla))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I know Bangla.', '[start] আমি বাংলা জানি. [end]')\n",
      "('Bangla is my mother tounge.', '[start] বাংলা আমার মাতৃভাষা. [end]')\n",
      "('Bangladesh is a south-asian country.', '[start] বাংলাদেশ দক্ষিন এশিয়ার একটি দেশ. [end]')\n",
      "('Have you ever been to Bangladesh?', '[start] আপনি কি কখনো বাংলাদেশে গিয়েছেন? [end]')\n",
      "('Sorry.', '[start] দুঃখিত. [end]')\n",
      "('About seventy percentage of people are literate.', '[start] বাংলাদেশের প্রায় সত্তর ভাগ মানুষ স্বাক্ষর. [end]')\n",
      "('It is a Bangla to English translation file.', '[start] এটা বাংলা থেকে ইংরেজি অনুবাদের নথি. [end]')\n",
      "('I do not know him.', '[start] আমি উনাকে চিনি না. [end]')\n",
      "('It is a Bangla to English translation file.', '[start] এটা বাংলা থেকে ইংরেজি অনুবাদের নথি. [end]')\n",
      "('It is a Bangla to English translation file.', '[start] এটা বাংলা থেকে ইংরেজি অনুবাদের নথি. [end]')\n",
      "('Sorry.', '[start] দুঃখিত. [end]')\n",
      "('It is a Bangla to English translation file.', '[start] এটা বাংলা থেকে ইংরেজি অনুবাদের নথি. [end]')\n",
      "('No.', '[start] না. [end]')\n",
      "('I do not know him.', '[start] আমি উনাকে চিনি না. [end]')\n",
      "('21st of February is the International Mother Language Day.', '[start] একুশে ফেব্রুয়ারি আন্তর্জাতিক মাতৃভাষা দিবস. [end]')\n",
      "('No.', '[start] না. [end]')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for i in range(len(text_pairs)):\n",
    "    print(random.choice(text_pairs));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(text_pairs)\n",
    "total_data_length = len(text_pairs)\n",
    "num_val_samples = int(0.15 * total_data_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_samples = (total_data_length - (2 * num_val_samples))\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
    "test_pairs = text_pairs[num_train_samples + num_val_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import string\n",
    "import re\n",
    "\n",
    "strip_chars = string.punctuation + \"?\"\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[!\"\\\\#\\\\$%\\\\&\\'\\\\(\\\\)\\\\*\\\\+,\\\\-\\\\./:;<=>\\\\?@\\\\\\\\\\\\^_`\\\\{\\\\|\\\\}\\\\~\\\\?]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"[{re.escape(strip_chars)}]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return(tf.strings.regex_replace(\n",
    "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\"\n",
    "    ))\n",
    "\n",
    "vocab_size = 10000\n",
    "sequence_length = 20\n",
    "source_vectorization = layers.TextVectorization(\n",
    "    max_tokens = vocab_size,\n",
    "    output_mode = \"int\",\n",
    "    output_sequence_length = sequence_length\n",
    ")\n",
    "target_vectorization = layers.TextVectorization(\n",
    "    max_tokens = vocab_size,\n",
    "    output_mode = \"int\",\n",
    "    output_sequence_length = sequence_length + 1,\n",
    "    standardize = custom_standardization\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_english_texts = [pair[0] for pair in train_pairs]\n",
    "train_bangla_texts = [pair[1] for pair in train_pairs]\n",
    "source_vectorization.adapt(train_english_texts)\n",
    "target_vectorization.adapt(train_bangla_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "def format_dataset(eng, ban):\n",
    "    eng = source_vectorization(eng)\n",
    "    ban = source_vectorization(ban)\n",
    "    return({\"english\": eng, \"bangla\": ban[:, :-1]}, ban[:, 1:])\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    eng_texts, ban_texts = zip(*pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    ban_texts = list(ban_texts)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, ban_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset, num_parallel_calls = 4)\n",
    "    return(dataset.shuffle(2048).prefetch(16).cache())\n",
    "\n",
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(list(train_ds.as_numpy_iterator()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs['english'].shape: (12, 20)\n",
      "inputs['bangla'].shape: (12, 19)\n",
      "target.shape: (12, 19)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f\"inputs['english'].shape: {inputs['english'].shape}\")\n",
    "    print(f\"inputs['bangla'].shape: {inputs['bangla'].shape}\")\n",
    "    print(f\"target.shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "embed_dim = 256\n",
    "latent_dim = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
    "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(source)\n",
    "encoded_source = layers.Bidirectional(layers.GRU(latent_dim), merge_mode=\"sum\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_target = keras.Input(shape=(None,), dtype=\"int64\", name=\"bangla\")\n",
    "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(past_target)\n",
    "decoder_gru = layers.GRU(latent_dim, return_sequences=True)\n",
    "x = decoder_gru(x, initial_state=encoded_source)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "target_next_step = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "seq2seq_rnn = keras.Model([source, past_target], target_next_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seq2seq_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 22s 22s/step - loss: 2.9095 - accuracy: 0.0000e+00 - val_loss: 2.1079 - val_accuracy: 0.7778\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.7871 - accuracy: 0.8333 - val_loss: 1.5239 - val_accuracy: 0.7778\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.3435 - accuracy: 0.8333 - val_loss: 0.5896 - val_accuracy: 0.7778\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3356 - accuracy: 0.8333 - val_loss: 0.6209 - val_accuracy: 0.4444\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4784 - accuracy: 0.2778 - val_loss: 0.6181 - val_accuracy: 0.7778\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3400 - accuracy: 0.8333 - val_loss: 0.5532 - val_accuracy: 0.7778\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2449 - accuracy: 0.8333 - val_loss: 0.5153 - val_accuracy: 0.7778\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1961 - accuracy: 0.8333 - val_loss: 0.4937 - val_accuracy: 0.7778\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1801 - accuracy: 0.8333 - val_loss: 0.4796 - val_accuracy: 0.7778\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1749 - accuracy: 0.8194 - val_loss: 0.4641 - val_accuracy: 0.7778\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1501 - accuracy: 0.8333 - val_loss: 0.4517 - val_accuracy: 0.7778\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1501 - accuracy: 0.8333 - val_loss: 0.4316 - val_accuracy: 0.7778\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1523 - accuracy: 0.8333 - val_loss: 0.5092 - val_accuracy: 0.5556\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2579 - accuracy: 0.5139 - val_loss: 0.4879 - val_accuracy: 0.7778\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2289 - accuracy: 0.8333 - val_loss: 0.4557 - val_accuracy: 0.7778\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1366 - accuracy: 0.8472 - val_loss: 0.4428 - val_accuracy: 0.7778\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1203 - accuracy: 0.8333 - val_loss: 0.4280 - val_accuracy: 0.7778\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1259 - accuracy: 0.8194 - val_loss: 0.4179 - val_accuracy: 0.7778\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0969 - accuracy: 0.8333 - val_loss: 0.4057 - val_accuracy: 0.7778\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1060 - accuracy: 0.8333 - val_loss: 0.4078 - val_accuracy: 0.7778\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0870 - accuracy: 0.8750 - val_loss: 0.3845 - val_accuracy: 0.7778\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2966 - accuracy: 0.8333 - val_loss: 0.5177 - val_accuracy: 0.5556\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2090 - accuracy: 0.5972 - val_loss: 0.4430 - val_accuracy: 0.7778\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2308 - accuracy: 0.8333 - val_loss: 0.4150 - val_accuracy: 0.7778\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1085 - accuracy: 0.8333 - val_loss: 0.4155 - val_accuracy: 0.7778\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1029 - accuracy: 0.8611 - val_loss: 0.4042 - val_accuracy: 0.7778\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1061 - accuracy: 0.8472 - val_loss: 0.4185 - val_accuracy: 0.6667\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0919 - accuracy: 0.8750 - val_loss: 0.3931 - val_accuracy: 0.7778\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1332 - accuracy: 0.8333 - val_loss: 0.4610 - val_accuracy: 0.5556\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1499 - accuracy: 0.7639 - val_loss: 0.4225 - val_accuracy: 0.7778\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1584 - accuracy: 0.8333 - val_loss: 0.4199 - val_accuracy: 0.8889\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0975 - accuracy: 0.8750 - val_loss: 0.4064 - val_accuracy: 0.7778\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0866 - accuracy: 0.8333 - val_loss: 0.4205 - val_accuracy: 0.7778\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0907 - accuracy: 0.8333 - val_loss: 0.4052 - val_accuracy: 0.7778\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1105 - accuracy: 0.8472 - val_loss: 0.5052 - val_accuracy: 0.5556\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2447 - accuracy: 0.5278 - val_loss: 0.4391 - val_accuracy: 0.7778\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1662 - accuracy: 0.8333 - val_loss: 0.4151 - val_accuracy: 0.7778\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1072 - accuracy: 0.8333 - val_loss: 0.4145 - val_accuracy: 0.7778\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0869 - accuracy: 0.8472 - val_loss: 0.4143 - val_accuracy: 0.7778\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0730 - accuracy: 0.8750 - val_loss: 0.4204 - val_accuracy: 0.7778\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0814 - accuracy: 0.8611 - val_loss: 0.4302 - val_accuracy: 0.7778\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0560 - accuracy: 0.9722 - val_loss: 0.4255 - val_accuracy: 0.7778\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0686 - accuracy: 0.8750 - val_loss: 0.5329 - val_accuracy: 0.6667\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2893 - accuracy: 0.5556 - val_loss: 0.4458 - val_accuracy: 0.7778\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1304 - accuracy: 0.8333 - val_loss: 0.4269 - val_accuracy: 0.7778\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0896 - accuracy: 0.8750 - val_loss: 0.4276 - val_accuracy: 0.7778\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0868 - accuracy: 0.8333 - val_loss: 0.4224 - val_accuracy: 0.7778\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0653 - accuracy: 0.8889 - val_loss: 0.4273 - val_accuracy: 0.7778\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0597 - accuracy: 0.9028 - val_loss: 0.4757 - val_accuracy: 0.6667\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1196 - accuracy: 0.8333 - val_loss: 0.4462 - val_accuracy: 0.7778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e340616c70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq_rnn.compile(\n",
    "    optimizer = \"rmsprop\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "seq2seq_rnn.fit(train_ds, epochs=50, validation_data=val_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24d7359adec4ffe2916680474ceb48a86338759ffb8252cd67d6683f84078a4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
